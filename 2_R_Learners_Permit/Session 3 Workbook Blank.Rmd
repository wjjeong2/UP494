---
title: "Session 3 Workbook"
author: "Andrew J. Greenlee, Ph.D."
date: "February 2, 2021"
output:
  html_notebook:
    toc: yes
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
---

R notebook can include texts and R codes together and do some preview as well :)

# Lab Introduction
This lab will serve as your initial introduction to the R programming language and RStudio development environment. We will work on this over the course of the week.

## Lab Description
For new users, R can be an intimidating programming language to learn, especially compared to other popular data analysis tools:

```{r X_LearningCurve, echo=FALSE, fig.cap="Learning Curves for Popular Data Analysis Tools ", out.width = '20%'}
knitr::include_graphics("Images/1_LearningCurve.png")
```

At the same time, there are some *really good* reasons to gain familiarity with R and RStudio, particularly within the context of urban planning analysis.

- R and RStudio are **open source tools**, and are therefore available to be downloaded and used without cost (this does not negate questions regarding *accessibility* of the language, given its steep learning curve)
- R and RStudio are supported by a wide range of users who develop packages for **specific use cases**, including those that are useful for urban planning analysis (we will spend more time learning about packages later in this lab)
- R and RStudio provide a framework for **reproducible data manipulation and analysis** - rather than sharing output with others, we can share raw data and code and they can reproduce our output

Thinking about the type of analysis we will do in this class, there are some additional rationales for learning and working in R and RStudio:

- R has a powerful set of functions for **aggregating and manipulating** many data records into a smaller number of summary records - we use these types of functions frequently to summarize neighborhood characteristics
- R can natively read from and write to **many types of data sources** - this allows us to perform most or all of our analysis within a single application rather than passing data between applications for different types of manipulation or analysis
- R can help us to **automate elements of data visualization**, which can be useful when we need to reproduce forms of analysis for different places or other data categories
- Looking beyond the reasons to use R and RStudio as a platform for analysis, these tools represent one of several programming languages frequently used for data science (the other main language being Python) - learning these languages prepares you for future interface with other data science tools and strategies

With the basic rationale laid out, let's start exploring the logic behind the R language:

## Lab Goals

 By the end of this lab, you should be familiar with:
 
 - The RStudio console and R language
 - R data types and structures
 - Basic data manipulation and querying

# R Basics
As a programming language, R was initially designed to be run in a terminal console. You can still run R in this fashion, if you wish. RStudio is an integrated development environment for R - in addition to providing us with a terminal window in which we could run commands, it also provides additional windows for viewing data and visualizations.

Here is one way to think of the relationship between R and RStudio"

```{r X_Analogy, echo=FALSE, fig.cap="R and RStudio Analogy", out.width = '100%'}
knitr::include_graphics("Images/2_rstudio_analogy.jpg")
```
If you grew up in the 1980s (as your humble professor did), you might consider the DeLorean to be a fairly cool car. This is R - it can do cool things, especially if you know how to use it well. Modify the DeLorean with lots of extra features (including time travel) and you have RStudio - add ons that build upon the strengths of R (so far as we know, RStudio hasn't been used for time travel *yet*).

It is important that we keep these things in mind, because they will help us to understand what its like to interact with R *via* RStudio. Let's start with a very basic way of interacting with R. Here is what the basic RStudio interface looks like:

```{r X_RStudio Interface, echo=FALSE, fig.cap="RStudio Interface", out.width = '100%'}
knitr::include_graphics("Images/3_4pane.png")
```

- The **Source** pane is where you will write and view scripts that provide instructions to the *console*.
- The **Console / Terminal** pane is the where you can view the execution of commands. You can directly type commands here and then click control / command + enter to run. More typically, you'll execute lines of code from within your scripts or the source pane.
- THe **Environment** pane allows you to view datasets loaded into memory and other objects which you have defined. You can also see a few basic characteristics of existing R objects.
- The **Auxiliary** pane which has multiple tabs. You will most often use this to view output, or load help documentation.

# R Notebooks
We are working in a special kind of document called an *R Notebook*. Our R Notebook allows us to integrate plain text with chunks of code.

The benefit of working in a notebook is that you can run code *in line* with your text, and see the results integrated with your writing kind of like a scientific lab notebook. Some people will use R Notebooks to write reports, since they can render tables and figures in line with their text, and these can easily be updated if new data or parameters are supplied.

This is what a code chunk looks like:
```{r}
# Code Chunk

```
Any content inside of this code chunk will be interpreted by your R session in the terminal when you hit the green play button to the right. You can also step through each line of code by putting your cursor to the right of it and hitting command+enter (Mac) or control+enter (PC) - I strongly recommend you get into the habit of running code this way at first.

You can create new code chunks by pressing control+option+I (Mac) or control+alt+I (PC).

In the above code chunk, we have some text preceded by a hashtag (`#`). Any content to the right of a hashtag (`# groundbreaking insightful comment`) will be considered a comment and will not be interpreted as code. Comments are a great way to make short notes to remind yourself or others of what you're doing:

```{r}
# This is a comment
1+2 # This is also a comment in line with some active code
```

Let's start by entering a simple command - let's add together 2 and 2 and ask R to return the product.

```{r}
2+2
```
Entering ```2+2``` into our console window and then hitting command/control+enter asks R to process the request we have given it - it then gives us back an answer to our request. We could of course do the same thing with other simple numeric operators:

- ```+``` Addition
- ```-``` Subtraction
- ```*``` Multiplication
- ```/``` Division
- ```^``` Exponents (e.g. ```2^3 = 8```)
- ```()``` Parentheses - to control order of operations (e.g. ```(2+3)/5 = 1)

We can do basic math in a console - not terribly exciting, but at least this helps you to see how R will respond to basic commands:
```{r}
2+2
2^3
(2+3)/5
```

Now your turn - create a code chunk in line here (remember, control + option + I), and perform some simple math operations. Also explore how R handles order of operations.

**Insert your code chunk here**

In most cases, we don't want to just type things into the console and then get an answer - we'd be just as well served with a calculator. Our next step is to understand that R can store the output of a command for later use. The most basic way to do this is to *assign* our output to an object. we can do this using the `<-` assignment operator:
```{r}
x <- 2+2
```

Let's learn how to speak this out. We just told R, into an object we have (arbitrarily) named "x", store the output of 2 + 2. Because this is now stored, we can retrieve it and use it later. If we simply ask for "x" R will share with us the previously assigned output - ` 2+2`

Option+- (Mac) or Alt + - (PC) is the shortcut for inserting the assignment operator.

```{r}
x
```
This means that we could also use this output in other formulas. Let's see what happens if we square X:
```{r}
x^2
```

Since X is 4, we get the output that is the equivalent of typing ``` 4^2```.

It is important to note here that we can provide any type of label we'd like for an R variable. Instead of using "x" as a variable name, we could use anything else.

Assign the sum of 4+6 into a variable named "cat".
```{r}
# Your Work Here
cat <- 4+6
```

We just assigned to a variable called "cat" the product of 4+6. To retrieve the value of your assigned variable, you can just call it by name:
```{r}
cat
```
R allows you to name variables as you wish. Note that variables need to start with a character, and cannot start with a number (e.g. 1_Numbers would not work). Also note that you will want to avoid variable names that are the same as R functions (so naming a variable "mean" for instance, would not be a good idea, as this would cause confusion with the function ```mean()``` which calculates the average of a vector).

We can of course work with multiple variables at once:
```{r}
cat+x
```
In this case, cat is 10 and x is 4 (you can see the values stored in objects in the environment pane). Let's divide cat+x by x:
```{r}
(cat+x)/x
```

This is great - we have a calculator that can store and make use of values as objects. Not so exciting for neighborhood analysis just yet, though...

The next thing to note is that objects don't have to be single values. We could also assign lists of values to an object:
```{r}
col1 <- c(2, 3, 4, 5, 6)
```
Note here that `c()` (formally the concatenate function) is used to denote that we have a list. Each list item it separated by commas. If we call up this object, we can have a look at our list:
```{r}
col1
```
Working with a single object, we could do things by using the object in a formula. We can do the same with a list:
```{r}
col1+2
```
To each list item, we added 2. We could even store this as a new object if we wanted 2
```{r}
col2 <- col1+2
```

Writing this out, we told r "Place into an object called "col2" the product of adding 2 to each item in the list contained in "col1".

```{r}
col2
```
Cool! We can manipulate our list items all at once. 

We can also have R automatically create *sequences* of numbers for us, if they follow a regular pattern using the `seq()` command:
```{r}
seq(0,100, 5)
```
This says create a list containing the sequence of numbers from 0 to 100 counting by fives.

Try creating your own sequence - count *up* from 4 to 24 by 4 
```{r}
# Your Work Here 
seq(4, 24, 4)
```

Try creating your another sequence - count *down* from 50 to 2 by 4. How would you do this?
```{r}
# Your Work Here
seq(50, 2, -4)
```

But we digress - back to our existing lists. What would happen if we decided to multiply col1 by col2?

```{r}
col1*col2
```
Can you see what happens here? Since our lists are the same size, R multiples the first item in col1 by the first item in col2, the second item in col1 by the second item in col2, and so on - e.g. (2*4, 3*5 ...)

Lists, however, don't have to be just numeric - they can be other types of things as well:

- **Numeric:** Values containing integers (positive or negative whole numbers such as 1, 10, 25840) or double values (any real number such as 1, 2.14, 3.254, -12). Double values may also include some special classes such as Inf, -Inf, and NaN - "positive infinity", "negative infinity", and "not a number".
- **Logical:** Logical values including TRUE, FALSE, and NA. TRUE and FALSE are self-explanatory. NA stands for "not available", which should not be confused with NULL, which is no value.
- **Character:** Also known as strings, these consist of text or text-like information. In R, we tend to surround strings by quotation marks to denote them. For instance, ```c("Black Cat", "Brown Dog", "Dappled Donkey", "Red Rooster")``` is a character vector containing four items.

We'll talk about some other types of vectors later, but these are sufficient to get you started. In addition to numeric vectors, probably the most common other type of vectors we will encounter are character vectors. Let's make a list of the items we need to make a single serving of oatmeal (your professor is hungry as he writes this lab):

```{r}
c("Oatmeal", "Water", "Salt", "Sugar")
```
In a separate list, let's place the quantity of ingredients:
```{r}
c(1/2, 1, .25, 1)
```
Perhaps it would be useful to make a third list with the unit of measure for the quantity of ingredients:
```{r}
c("Cup", "Cup", "Teaspoon", "Tablespoon")
```

Okay, we have three lists, that we might be able to use for different things. Write code that assigns the list of ingredients to a new object called "ingredients", write the quantities to a new object called "quantity", and write the units to a new object called "units".
```{r}
# Your Work Here
quantity <- c(1/2, 1, .25, 1)
ingredients <- c("Oatmeal", "Water", "Salt", "Sugar")
units <- c("Cup", "Cup", "Teaspoon", "Tablespoon")

```

We could do some interesting things here, like paste together the different list items into something approximating a recipe:
```{r}
paste(quantity, units, ingredients, sep=" ")
```

What is `sep = " "` doing here? What would happen if you changed `sep` to a comma?

You can take a look at the documentation for the `paste()` command by typing `?paste`.

Verbalizing what we just asked R to do (a valuable habit for problem solving more complex functions and data manipulation later on), we said "paste together the list items contained in the variables quantity, units, and ingredients, placing a space between each of the list items."

We can also manipulate list objects - let's say you volunteer to host a community meeting and need to make 45 portions of your oatmeal recipe - how would you go about constructing your grocery list? Below, write out the operations that you would need to do to modify your existing list of quantities to account for 45 portions (let's assume that ingredient quantities remain the same when we scale up our recipe):

Since you're new at this, here are few ways to do this (I hope you've tried on your own to figure it out on your own before reading on) - you could either modify the quantities in the quantity vector by multiplying them directly and creating a new vector:
```{r}
quantity45 <- quantity*45
paste(quantity45, units, ingredients, sep=" ")
```
Alternately, you could modify the list directly in your paste command:
```{r}
paste(quantity*45, units, ingredients, sep=" ")
```

The outputs are exactly the same.

R can also help us to pick out list items. The brackets `[]` allow us to return list items by position (left to right).

```{r}
ex_list<-c("Jane", "Jacobs", "beats", "Robert", "Moses", "in", "a", "fight", "for", "New York")

ex_list[4]
```
What would happen if we put `[-4]` instead of 4?

```{r}
# Your Work Here
ex_list[-4] #excluding "4(Robert)"
```

Now you try selecting the tenth element from the list.
```{r}
# Your Work Here
ex_list[10]
```

We can also select multiple elements at the same time:
```{r}
ex_list[c(4, 5, 3, 1, 2)]
```

We created a list `c()` and placed it in brackets which told R that we wanted to return the values of `ex_list` that corresponded to the positions in our other list `c(4, 5, 3, 1, 2)`.

Now you try creating and manipulating a list.

```{r}
# Your Work Here
ex_list2 <- c("Gina", "apple", "the best", "Chicago", "in", "makes", "pie")
ex_list2[c(1, 6, 3, 2, 7, 5, 4)]

```

Now re-create the sequence you crafted earlier (count *up* from 4 to 24 by 4) and subset out the fifth element from that numeric sequence:
```{r}
# Your Work Here
seq(4, 24, 4)[5]

```

Fun (maybe), but not yet particularly useful. You didn't take this class because you wanted to scale oatmeal recipes or identify numbers in a sequence. The more powerful stuff is coming up! - these are building blocks to teach some of the logic of the language.

The next thing for us to think about is how we might combine lists together. Thinking back to our oatmeal recipe, right now we have three separate lists each (respectively) with our quantity, units, and ingredients. We've figured out that we can paste together items from different lists, but it might be nice to be able to store them in one object rather than three. This is a good time to introduce the R data frame, which is the object you'll be dealing with the most.

Start by looking at R's internal documentation on data frames (`?data.frame`):

:
```{r}
# Your Work Here
?data.frame
```

Now lets *coerce* our three lists into a single data frame called "oatmeal":
```{r}
oatmeal <- data.frame(quantity, units, ingredients, stringsAsFactors = FALSE)
oatmeal
```
We created a new object called "oatmeal" that has bound our three lists together into a *data frame*. We need to specify `stringsAsFactors = FALSE` to keep R from turning our strings (characters) into a special data type called factors (more on these later). R assumes that we want our columns labeled with the original list object names.

We can now look at our list as a series of columns that have been given the name of the variable they were stored in as a list, and each row represents one of the list items. An important concept to keep in mind is that a data frame is a series of lists that are in essence glued together.

We can refer to and access rows and columns in our data frame in several ways. If we want to return those items in a specific column if the list, we can use the `$` operator to refer to that item:

```{r}
oatmeal$ingredients
```
We just returned the list items that were in the column named ingredients. We could also use our subset notation to retrieve the same things. This subset notation builds upon what we learned when we accessed list items by position (e.g. `units[2]`):
```{r}
knitr::include_graphics("Images/04_guru99_dataframe.png")
```


While subsets of lists require one number corresponding to the index position, data frames have *two dimensions* - rows and columns, so we need to be able to differentiate between each. R does this using a comma in the subset notation `[row, column]`. If we want all rows or columns, we can just leave that portion of the bracket empty. For instance, the code below is the equivalent of typing `oatmeal$ingredients` since ingredients are the third column in the oatmeal data frame:
```{r}
oatmeal[,3]
```
This is because ingredients is the third column in the oatmeal data frame.

Now you try: query the *second row* of the oatmeal data frame:
```{r}
# Your Code Here
oatmeal[2,]
```

How would you query the third row of the second column?
```{r}
# Your Work Here
oatmeal[3,2]
```

Ok, so we see that we can create subsets fairly easily, either using column names or index positions in our dataset.

We can add new columns to our data frame. Oftentimes when we are working with data, we'll need to calculate a new column based upon the values in other columns. We have our data frame with a recipe for 1 serving of oatmeal. Let's say we frequently need to make 45 servings of oatmeal (its famous, and the reason why people show up to your 7am neighborhood meetings...), so you want to include that quantity alongside the single serving quantity.

Let's create a new column called "quantity45" and add to it the quantity of ingredients for a 45 serving batch of oatmeal:
```{r}
oatmeal$quantity45 <- oatmeal$quantity*45

oatmeal
```

Note that we need to refer to the original quantity by pointing to the oatmeal data frame as well. Let's verbalize this to think about what we're doing. "Into a new column in the oatmeal data frame called quantity45 (`oatmeal$quantity45 <-`), write the value contained in the oatmeal data frame called quantity multiplied by 45 (`oatmeal$quantity*45`)."

Now you try - create a new column called "instructions" in the oatmeal data table that contains our recipe quantity for 45 portions of oatmeal, units, and ingredients pasted together (this will require you reference data using concepts we learned earlier):

```{r}
# Your Work Here
oatmeal$instructions <- paste(quantity*45, units, ingredients, sep = " ")
oatmeal$instructions 
```

Note again that we need to refer to each of the specific columns in the oatmeal data frame using their appropriate vector (e.g. `oatmeal$ingredients`. Note that in this case if we omitted the pointer to oatmeal, R would assume we wanted to do something with the list called ingredients. In this case, that would actually work, but in most cases, we will just have a data frame and won't have a separate list stored as an R object - we'd get an error.

We can also pull out all items meeting a specific criteria in our data frame - let's say we want to look at those ingredients that are measured in cups:

```{r}
oatmeal[oatmeal$units == "Cup",]
```
This looks weird - we've introduced some new notation here. Let's first speak this out and then we can learn more about the notation. "From the oatmeal data frame, return those rows from within the oatmeal data frame for which the value of the units column is equal to "Cup" (the equal sign in R is `==` two equal signs together).Notice also that the word "Cup" has parentheses surrounding it, denoting that it is a character string. The square brackets `[]` denote that we're looking for something (or some things) within the oatmeal data frame. 

While in this case, we're looking for rows that meet a specific criteria based upon the word "Cup" (searching for a character string), we could return subsets of numeric records in other ways:

```{r}
oatmeal[oatmeal$quantity > .5,]
```
Returns those records from the oatmeal data frame for which the quantity value is greater than .5. If we wanted to include our .5 cups of water, we could specify ```>=``` (greater than or equal to).

```{r}
oatmeal[oatmeal$quantity >= .5,]
```

# Time to Practice
Let's stop playing around with hypothetical oatmeal recipes, and get our hands on some "real world" data!

## The Data
We're going to work with data on those census tracts that were designated as Opportunity Zones as part of the federal Tax Cuts and Jobs Act. These incentives are designed to spur investment in low-income and under-capitalized cities, by providing investors with tax incentives to invest capital in these locations.

We're going to practice working with data frames and tibbles by using data census tracts that are designated as Opportunity Zones by the US Treasury. The 2017 [Tax Cuts and Jobs Act](https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.pdf) included a new federal incentive to spur investment in low-income and undercapitalized communities. Each state had the opportunity to designate specific census tracts as Opportunity Zones. Practitioners and researchers have [many questions](https://www.urban.org/policy-centers/metropolitan-housing-and-communities-policy-center/projects/opportunity-zones) about the efficacy of the program and the designations made by governors.

Take a look [here](https://opportunityzones.hud.gov/resources/map) to see a map of where opportunity zones are located. The pink geometries reflected on the map are [census tracts](https://www.census.gov/programs-surveys/geography/about/glossary.html#par_textimage_13), which we often use as a proxy for neighborhoods, especially in urban areas. Find a place you know, and take a look at which areas are designated.

A copy of the Urban Institute's dataset (which contains the underlying data for this map as well as some other analysis) is downloaded and is in the "data" folder as part of this lab's project. We could have R download it directly, but that's for another class session!

## Loading Required Packages
We're been working primarily in "base" R as we are getting familiar with the R language and RStudio interface. In this lab, we'll introduce tools that extend the functionality of the base R syntax.

Let's start by loading a package which will help us to work through loading data. Specifically, we'll load the `readxl` package which contains tools which will help us to read Excel files into R.

Go ahead and put your new knowledge to use. Use `install.packages()` to download the readxl packages and then use `library()` to load it into for your R session:
```{r}
# Your work here
library(readxl)
```

- In general, you will only need to use `install.packages()` once (once a package is installed, you can use it for all R sessions moving forward). 
- To load packages, we use the `library()` command. This will load an already installed package and make it accessible within our current R session. You will need to load already installed packages at the beginning of each new R session. Typically, it is a good practice to load the packages you'll use in a script at the beginning of the script.

Note that to install the package, you need to treat the package name as a character vector `"readxl"`, but when you load it in your R session, it does not need to be treated as a character vector`readxl`.

# Read in Data

Now that we've loaded the packages that we need to work with, we can import the excel file containing data on tracts designated as opportunity zones in the United States.

We downloaded the `readxl` package, which is designed to read Excel files into R data frames. You can either do a Google search for [Readxl](https://readxl.tidyverse.org) to find documentation, or you can use R's built in documentation by typing `?readxl`
```{r}
# Your work here
?readxl
```
As the documentation states, `readxl` imports excel files. Looking at the documentation, the `read_excel()` command will read a single excel sheet, or we can optionally select a sheet by name or number from an excel workbook with multiple sheets. In this case, the Urban Institute data is in a workbook with a single sheet, so we just need to tell R where the file is to load.

The dataset we want to load is called "urbaninstitute_tractlevelozanalysis_update1242018.xlsx" (oof! - that's a descriptive but way too long file name!). We can point R to the correct location. Since our R project file sets the relative path for all of the work within, the path to the data is:`"data/urbaninstitute_tractlevelozanalysis_update1242018.xlsx"`. Wrapped into the command to read the excel file, it looks like this: 
```{r, eval=FALSE}
read_excel("data/urbaninstitute_tractlevelozanalysis_update1242018.xlsx")
```
R read the data and is displaying it to us.

Now go ahead and read the Excel data into an object called "ozs":
```{r}
# Your Work Here
ozs <- read_excel("data/urbaninstitute_tractlevelozanalysis_update1242018.xlsx")

```

Look at your Environment window (top right quadrant of RStudio) - a data frame containing information on opportunity zones should be loaded in an object called "ozs".

The environment window tells us that the object ozs contains 42,176 observations (rows) and 27 variables (columns).

Inspect the dataset using the ```View()``` command. This will allow us to look at the data in a tabular format.
```{r}
View(ozs)
```

Now, use the str() command to gain a better understanding of the *types* of data in each column
```{r}
str(ozs)
```

We get a list of the columns in the data, along with their types (in this case character or numeric), and then we see the values associated with the first few observations. 

A few things to note after your preliminary inspection:

- These data are at the census tract level and include geographic identifiers including **geoid**, the combined, state-county-tract FIPS code, **state** the state name, and **county** the county name.
- These data include a field named **Designated** which is 1 when an eligible tract was designated as an opportunity zone, and `NA` where the tract was not designated.
- The dataset also includes some other tract-level demographic measures, as well as additional geographic flags.

# Describing the Data

R has several functions for determining the structure of data frames and tibbles. See below:

**Size**

- `dim(ozs)`: returns a vector with the number of rows in the first element, and the number of columns as the second element (the dimensions of the object)
- `nrow(ozs)`: returns the number of rows
- `ncol(ozs)`: returns the number of columns

**Content**

- `head(ozs)`: shows the first 6 rows
- `tail(ozs)`: shows the last 6 rows

**Names**

- `names(ozs)`: returns the column names

**Summary**

- `str(ozs)`: structure of the object and information about the class, length and content of each column
- `summary(ozs)`: summary statistics for each column

Try your hand at some of these summarization methods to see what they produce:
```{r}
# Your Work Here
dim(ozs)
nrow(ozs)
ncol(ozs)
head(ozs)
tail(ozs)
names(ozs)
summary(ozs)

```

## Summaries
Now that we have a real live dataset loaded into R, we probably want to describe what it is. We can use a function like `summary()` to take a closer look at some of the properties of the data:

```{r}
summary(ozs)
```
We get a column by column summary based upon the type of data which R "sees" in each column in the ozs data. For character columns, this includes the length (number of observations) and type of data (character in this case). For numeric columns, we get some descriptive statistics, including the number of records that area `NA` or have no value.

How would we run summaries just for population, median household income, and poverty rate (think back to how we created subsets using lists)?

```{r}
# Your Work Here
summary(ozs$Population)
summary(ozs$medhhincome2014_tract)
summary(ozs$PovertyRate)

summary(ozs[, c("Population", "medhhincome2014_tract", "PovertyRate")])

```

Next up, practice your querying skills - how would we return only those records for census tracts with a median household income above $100,000 per year?

```{r}
# Your Work Here

ozs[ozs$medhhincome2014_tract>=100000,] #399

```

How would we query out tracts in Illinois?

```{r}
ozs[ozs$state == "Illinois",]
```

We can see in our table output that there are 1,682 eligible or designated tracts in Illinois. We could also use the `nrow()` command to count the number of rows. Try crafting code that would count the number of rows for Illinois:

```{r}
# Your Work Here
nrow(ozs[ozs$state == "Illinois",])

```

## Mean
We might also want to calculate statistics like averages for subsets. `mean()` will calculate the mean of a list or column. What's the average income for tracts with a vacancy rate above 20 percent? What's the average income for tracts with a vacancy rate below 20 percent?

```{r}
# Your Work Here
mean(ozs$medhhincome2014_tract[ozs$vacancyrate > .2], na.rm = TRUE) #35375.6
mean(ozs$medhhincome2014_tract[ozs$vacancyrate < .2], na.rm = TRUE) #43849.18

```

You might need to check out the documentation for `mean()` in order to return an answer here. R will not calculate the mean if an `NA` values are present in the vector for which you've requested the mean - a good safety feature if you're expecting all values to be present. In imperfect data like what we're dealing with, you can instruct R to remove those NAs and find the mean for remaining values. You may also want to make sure you've counted the number of NA values so you know what proportion of your data the mean is actually representing.

## Subsetting
We might also be interested in combining query criteria. How would we determine the average income for tracts in Illinois with a poverty rate of greater than 20 percent?

- R can make use of logical statements. `&` is equivalent to AND and `|` is equivalent to OR. Now give it a go!

```{r}
# Your Work Here
mean(ozs$medhhincome2014_tract[ozs$state == "Illinois" & ozs$PovertyRate > .2], na.rm = TRUE) #33526 
```

To confirm we got the query correct, have a look at the returned data (with out calculating the mean):
```{r}
# Your Work Here
ozs$medhhincome2014_tract[ozs$state == "Illinois" & ozs$PovertyRate > .2]
```

## Dealing with Missing Values

You'll note that there are several flag variables in the data for which values are either 1 or `NA`. We have flags for whether a tract was designated as an Opportunity Zone, Whether it is located in a Metropolitan, Micropolitan, or Non-Core-Based Statistical Area.

We can use logical tests in R to identify those values that are `NA`. We can use `is.na()` to test whether a value is NA (TRUE) or is not NA (FALSE). We could also use the negation sign `!` to determine whether a value *is not* `NA` (`!is.na()`).

The following code returns a vector of logical values (TRUE / FALSE) regarding whether the value for the Designated column is `NA` or not. 
```{r}
is.na(ozs$Designated)
```

For logical values, R codes 1 as TRUE and 0 as false, meaning if we wanted to count the number of undesginated tracts, we could simply ask for the sum of the values for which the logical test is true (the sum of the values that are `NA`):
```{r}
sum(is.na(ozs$Designated))
```
33,414 tracts were not designated.

Now count the number of tracts that were designated (where the value is not `NA`):
```{r}
# Your Work Here
sum(!is.na(ozs$Designated))

```

We might also want to recode those NA values to something else. We can use assignment and subset notation to replace na values with something else. Let's replace those NAs in the Designated column with 0.
```{r}
ozs$Designated[is.na(ozs$Designated)]<-0
ozs
```

Can you inspect the table here to see what happened? In plain language, we told R "for those values of the column named Designated in the ozs data table where the values are `NA`, assign a new value of 0."

Go ahead and do the same thing for the Metro, Micro, and NoCBSAType columns:
```{r}
# Your Work Here
ozs$Metro[is.na(ozs$Metro)]<-0
ozs$Micro[is.na(ozs$Micro)]<-0
ozs$NoCBSAType[is.na(ozs$NoCBSAType)]<-0

```

# Independent Exploration:

Now answer the following questions:

1. Report average poverty rates for *designated* opportunity zones in metropolitan, micropolitan, and non-CBSA areas
```{r}
# Your Work Here
mean(ozs$PovertyRate[ozs$Designated == 1 & ozs$Metro == 1], na.rm = TRUE) #.33 
mean(ozs$PovertyRate[ozs$Designated == 1 & ozs$Micro == 1], na.rm = TRUE) #.28 
mean(ozs$PovertyRate[ozs$Designated == 1 & ozs$NoCBSAType == 1], na.rm = TRUE) #.24
```
metropolitan = 33% 
micropolitan = 28% 
non-CBSA areas = 24%

2. For Illinois, how different are the average vacancy rates for *designated* and *undesignated* census tracts?
```{r}
# Your Work Here
mean(ozs$vacancyrate[ozs$state == "Illinois" & ozs$Designated == 1], na.rm = TRUE)
#.1840626 
mean(ozs$vacancyrate[ozs$state == "Illinois" & ozs$Designated == 0], na.rm = TRUE) #.1210847
```
6.3%

3. Think of another question you'd like to ask of these data - write it down and work the problem out.

** Description here **
How different are the average vacancy rates for Illiois and California?

According to our data, Illinois (13.35%) has higher average vacancy rates compared to California (7.96%). 

```{r}
# Your Work Here
mean(ozs$vacancyrate[ozs$state == "Illinois"], na.rm =TRUE) # .1335056
mean(ozs$vacancyrate[ozs$state == "California"], na.rm = TRUE)# .07956617
```

Congratulations! You are now well versed in the following:
 - The RStudio console and R language
 - R data types and structures
 - Basic data manipulation and querying
 
 Welcome to the nerd zone, my friends...
```{r}
knitr::include_graphics("Images/02_1_Nerd_Zone.gif")
```
 
Moving forward, we'll explore some more advanced strategies for summarizing data.